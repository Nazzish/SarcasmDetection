{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "import math\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer, \n",
    "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                                  DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer)\n",
    "\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (convert_examples_to_features,\n",
    "                        output_modes, processors)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'do_eval': True,\n",
    "    'data_dir': 'data-sarcasm/',\n",
    "    'output_dir': 'outputs',\n",
    "    'model_dir': 'ensembles_models/',\n",
    "    'task_name': 'binary',\n",
    "    'eval_batch_size': 12,\n",
    "    'eval_all_checkpoints': True,\n",
    "    'max_seq_length': 128,\n",
    "    'output_mode': 'classification',\n",
    "    'reprocess_input_data': True\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "\n",
    "if task in processors.keys() and task in output_modes.keys():\n",
    "    processor = processors[task]()\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels = len(label_list)\n",
    "else:\n",
    "    raise KeyError(f'{task} not found in processors or in output_modes. Please check utils.py.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, model_type, model_name):\n",
    "    processor = processors[task]()\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    mode = 'dev'\n",
    "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{model_name}_{args['max_seq_length']}_{task}\")\n",
    "    \n",
    "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "               \n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
    "        label_list = processor.get_labels()\n",
    "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
    "        \n",
    "        if __name__ == \"__main__\":\n",
    "            features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "                cls_token_at_end=bool(model_type in ['xlnet']),            # xlnet has a cls token at the end\n",
    "                cls_token=tokenizer.cls_token,\n",
    "                cls_token_segment_id=2 if model_type in ['xlnet'] else 0,\n",
    "                sep_token=tokenizer.sep_token,\n",
    "                sep_token_extra=bool(model_type in ['roberta']),           # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                pad_on_left=bool(model_type in ['xlnet']),                 # pad on the left for xlnet\n",
    "                pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                pad_token_segment_id=4 if model_type in ['xlnet'] else 0)\n",
    "        \n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "        \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "def evaluate(model, tokenizer, model_type=\"bert\", model_name=\"bert-base-cased\", prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args['output_dir']\n",
    "\n",
    "    results = {}\n",
    "    EVAL_TASK = args['task_name']\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, model_type, model_name)\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if model_type not in ['distilbert']:\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'token_type_ids': batch[2] if model_type in ['bert', 'xlnet'] else None,\n",
    "                          'labels':         batch[3]}\n",
    "            else:\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer, 'bert-base-cased'),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer, 'xlnet-base-cased'),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, 'roberta-base'),\n",
    "    'distilbert':(DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluate the following checkpoints: ['ensembles_models/bert/checkpoint-2000', 'ensembles_models/bert/checkpoint-4000', 'ensembles_models/bert/checkpoint-6000', 'ensembles_models/bert', 'ensembles_models/distilbert/checkpoint-2000', 'ensembles_models/distilbert/checkpoint-4000', 'ensembles_models/distilbert', 'ensembles_models/roberta/checkpoint-2000', 'ensembles_models/roberta/checkpoint-4000', 'ensembles_models/roberta', 'ensembles_models/xlnet/checkpoint-2000', 'ensembles_models/xlnet/checkpoint-4000', 'ensembles_models/xlnet']\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "if args['do_eval']:\n",
    "    checkpoints = [args['output_dir']]\n",
    "    if args['eval_all_checkpoints']:\n",
    "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args['model_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluate the following model type: bert\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 10489.49it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_bert-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation 2000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea085eacc30c45598ed4e73996aef950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 2000 *****\n",
      "INFO:__main__:  fn = 785\n",
      "INFO:__main__:  fp = 418\n",
      "INFO:__main__:  mcc = 0.2797035315173321\n",
      "INFO:__main__:  tn = 1862\n",
      "INFO:__main__:  tp = 623\n",
      "INFO:__main__:Evaluate the following model type: bert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 12428.02it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_bert-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation 4000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c77090ba4ae4a85b3e4f065e56f222d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 4000 *****\n",
      "INFO:__main__:  fn = 786\n",
      "INFO:__main__:  fp = 418\n",
      "INFO:__main__:  mcc = 0.27901831286249507\n",
      "INFO:__main__:  tn = 1862\n",
      "INFO:__main__:  tp = 622\n",
      "INFO:__main__:Evaluate the following model type: bert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 12033.31it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_bert-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation 6000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7bfe339511488fb9f4ae2be94d79e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 6000 *****\n",
      "INFO:__main__:  fn = 893\n",
      "INFO:__main__:  fp = 374\n",
      "INFO:__main__:  mcc = 0.22913483769035498\n",
      "INFO:__main__:  tn = 1906\n",
      "INFO:__main__:  tp = 515\n",
      "INFO:__main__:Evaluate the following model type: bert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 10395.12it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_bert-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation ensembles_models/bert *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869df0d6d8714804a2753ba14ea386b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results ensembles_models/bert *****\n",
      "INFO:__main__:  fn = 892\n",
      "INFO:__main__:  fp = 374\n",
      "INFO:__main__:  mcc = 0.2298533874976484\n",
      "INFO:__main__:  tn = 1906\n",
      "INFO:__main__:  tp = 516\n",
      "INFO:__main__:Evaluate the following model type: distilbert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 9086.99it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_distilbert-base-uncased_128_binary\n",
      "INFO:__main__:***** Running evaluation 2000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc610cb3b6481e9d8b869ae8144beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 2000 *****\n",
      "INFO:__main__:  fn = 888\n",
      "INFO:__main__:  fp = 388\n",
      "INFO:__main__:  mcc = 0.22457836410984341\n",
      "INFO:__main__:  tn = 1892\n",
      "INFO:__main__:  tp = 520\n",
      "INFO:__main__:Evaluate the following model type: distilbert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 12052.12it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_distilbert-base-uncased_128_binary\n",
      "INFO:__main__:***** Running evaluation 4000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75be9fdf6004d83bed041a7b8f4d31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 4000 *****\n",
      "INFO:__main__:  fn = 804\n",
      "INFO:__main__:  fp = 423\n",
      "INFO:__main__:  mcc = 0.26385940441112005\n",
      "INFO:__main__:  tn = 1857\n",
      "INFO:__main__:  tp = 604\n",
      "INFO:__main__:Evaluate the following model type: distilbert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 12148.07it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_distilbert-base-uncased_128_binary\n",
      "INFO:__main__:***** Running evaluation ensembles_models/distilbert *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af53ca0a22484cf596a92cbe1f385160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results ensembles_models/distilbert *****\n",
      "INFO:__main__:  fn = 833\n",
      "INFO:__main__:  fp = 413\n",
      "INFO:__main__:  mcc = 0.24928365841491576\n",
      "INFO:__main__:  tn = 1867\n",
      "INFO:__main__:  tp = 575\n",
      "INFO:__main__:Evaluate the following model type: roberta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/azureuser/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 6298.92it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_roberta-base_128_binary\n",
      "INFO:__main__:***** Running evaluation 2000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437972d60d304e94af3709859a52e055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 2000 *****\n",
      "INFO:__main__:  fn = 707\n",
      "INFO:__main__:  fp = 484\n",
      "INFO:__main__:  mcc = 0.29711189778238034\n",
      "INFO:__main__:  tn = 1796\n",
      "INFO:__main__:  tp = 701\n",
      "INFO:__main__:Evaluate the following model type: roberta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/azureuser/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 5350.78it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_roberta-base_128_binary\n",
      "INFO:__main__:***** Running evaluation 4000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb46cb051bb4c0bb172c2fd605a696b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 4000 *****\n",
      "INFO:__main__:  fn = 741\n",
      "INFO:__main__:  fp = 472\n",
      "INFO:__main__:  mcc = 0.280447502625932\n",
      "INFO:__main__:  tn = 1808\n",
      "INFO:__main__:  tp = 667\n",
      "INFO:__main__:Evaluate the following model type: roberta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/azureuser/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/azureuser/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 6162.45it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_roberta-base_128_binary\n",
      "INFO:__main__:***** Running evaluation ensembles_models/roberta *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e737ef83d5b4509847c11f9dabe133e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results ensembles_models/roberta *****\n",
      "INFO:__main__:  fn = 722\n",
      "INFO:__main__:  fp = 478\n",
      "INFO:__main__:  mcc = 0.2901449944460227\n",
      "INFO:__main__:  tn = 1802\n",
      "INFO:__main__:  tp = 686\n",
      "INFO:__main__:Evaluate the following model type: xlnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/azureuser/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 15489.07it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_xlnet-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation 2000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a9395f67a245b9a6ea81dc80357ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 2000 *****\n",
      "INFO:__main__:  fn = 853\n",
      "INFO:__main__:  fp = 388\n",
      "INFO:__main__:  mcc = 0.24945436132706805\n",
      "INFO:__main__:  tn = 1892\n",
      "INFO:__main__:  tp = 555\n",
      "INFO:__main__:Evaluate the following model type: xlnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/azureuser/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 15722.13it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_xlnet-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation 4000 *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91312a054a954b0ca81367515238fa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results 4000 *****\n",
      "INFO:__main__:  fn = 907\n",
      "INFO:__main__:  fp = 345\n",
      "INFO:__main__:  mcc = 0.23630994091773264\n",
      "INFO:__main__:  tn = 1935\n",
      "INFO:__main__:  tp = 501\n",
      "INFO:__main__:Evaluate the following model type: xlnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/azureuser/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
      "INFO:__main__:Creating features from dataset file at data-sarcasm/\n",
      "100%|██████████| 3688/3688 [00:00<00:00, 15693.08it/s]\n",
      "INFO:__main__:Saving features into cached file data-sarcasm/cached_dev_xlnet-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation ensembles_models/xlnet *****\n",
      "INFO:__main__:  Num examples = 3688\n",
      "INFO:__main__:  Batch size = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c5bf120ead499fb1cc08ee1da0e410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results ensembles_models/xlnet *****\n",
      "INFO:__main__:  fn = 945\n",
      "INFO:__main__:  fp = 338\n",
      "INFO:__main__:  mcc = 0.21277562202875464\n",
      "INFO:__main__:  tn = 1942\n",
      "INFO:__main__:  tp = 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if args['do_eval']:    \n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
    "        model_type = checkpoint.split('/')[1]\n",
    "        logger.info(\"Evaluate the following model type: %s\", model_type)\n",
    "        \n",
    "        config_class, model_class, tokenizer_class, model_name = MODEL_CLASSES[model_type]\n",
    "        \n",
    "        config = config_class.from_pretrained(model_name, num_labels=2, finetuning_task=args['task_name'])\n",
    "        \n",
    "        model = model_class.from_pretrained(checkpoint)\n",
    "        model.to(device)\n",
    "        \n",
    "        tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "        \n",
    "        result, wrong_preds = evaluate(model, tokenizer, model_type, model_name, prefix=global_step)\n",
    "        result = dict((model_type + '_' + k + '_{}'.format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_fn_2000': 785,\n",
       " 'bert_fn_4000': 786,\n",
       " 'bert_fn_6000': 893,\n",
       " 'bert_fn_ensembles_models/bert': 892,\n",
       " 'bert_fp_2000': 418,\n",
       " 'bert_fp_4000': 418,\n",
       " 'bert_fp_6000': 374,\n",
       " 'bert_fp_ensembles_models/bert': 374,\n",
       " 'bert_mcc_2000': 0.2797035315173321,\n",
       " 'bert_mcc_4000': 0.27901831286249507,\n",
       " 'bert_mcc_6000': 0.22913483769035498,\n",
       " 'bert_mcc_ensembles_models/bert': 0.2298533874976484,\n",
       " 'bert_tn_2000': 1862,\n",
       " 'bert_tn_4000': 1862,\n",
       " 'bert_tn_6000': 1906,\n",
       " 'bert_tn_ensembles_models/bert': 1906,\n",
       " 'bert_tp_2000': 623,\n",
       " 'bert_tp_4000': 622,\n",
       " 'bert_tp_6000': 515,\n",
       " 'bert_tp_ensembles_models/bert': 516,\n",
       " 'distilbert_fn_2000': 888,\n",
       " 'distilbert_fn_4000': 804,\n",
       " 'distilbert_fn_ensembles_models/distilbert': 833,\n",
       " 'distilbert_fp_2000': 388,\n",
       " 'distilbert_fp_4000': 423,\n",
       " 'distilbert_fp_ensembles_models/distilbert': 413,\n",
       " 'distilbert_mcc_2000': 0.22457836410984341,\n",
       " 'distilbert_mcc_4000': 0.26385940441112005,\n",
       " 'distilbert_mcc_ensembles_models/distilbert': 0.24928365841491576,\n",
       " 'distilbert_tn_2000': 1892,\n",
       " 'distilbert_tn_4000': 1857,\n",
       " 'distilbert_tn_ensembles_models/distilbert': 1867,\n",
       " 'distilbert_tp_2000': 520,\n",
       " 'distilbert_tp_4000': 604,\n",
       " 'distilbert_tp_ensembles_models/distilbert': 575,\n",
       " 'roberta_fn_2000': 707,\n",
       " 'roberta_fn_4000': 741,\n",
       " 'roberta_fn_ensembles_models/roberta': 722,\n",
       " 'roberta_fp_2000': 484,\n",
       " 'roberta_fp_4000': 472,\n",
       " 'roberta_fp_ensembles_models/roberta': 478,\n",
       " 'roberta_mcc_2000': 0.29711189778238034,\n",
       " 'roberta_mcc_4000': 0.280447502625932,\n",
       " 'roberta_mcc_ensembles_models/roberta': 0.2901449944460227,\n",
       " 'roberta_tn_2000': 1796,\n",
       " 'roberta_tn_4000': 1808,\n",
       " 'roberta_tn_ensembles_models/roberta': 1802,\n",
       " 'roberta_tp_2000': 701,\n",
       " 'roberta_tp_4000': 667,\n",
       " 'roberta_tp_ensembles_models/roberta': 686,\n",
       " 'xlnet_fn_2000': 853,\n",
       " 'xlnet_fn_4000': 907,\n",
       " 'xlnet_fn_ensembles_models/xlnet': 945,\n",
       " 'xlnet_fp_2000': 388,\n",
       " 'xlnet_fp_4000': 345,\n",
       " 'xlnet_fp_ensembles_models/xlnet': 338,\n",
       " 'xlnet_mcc_2000': 0.24945436132706805,\n",
       " 'xlnet_mcc_4000': 0.23630994091773264,\n",
       " 'xlnet_mcc_ensembles_models/xlnet': 0.21277562202875464,\n",
       " 'xlnet_tn_2000': 1892,\n",
       " 'xlnet_tn_4000': 1935,\n",
       " 'xlnet_tn_ensembles_models/xlnet': 1942,\n",
       " 'xlnet_tp_2000': 555,\n",
       " 'xlnet_tp_4000': 501,\n",
       " 'xlnet_tp_ensembles_models/xlnet': 463}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
